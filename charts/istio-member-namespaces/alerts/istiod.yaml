# taken from https://github.com/istio/tools/blob/master/perf/stability/alertmanager/prometheusrule.yaml
groups:
- name: istiod-controlplane-rules
  rules:
  - alert: IstiodXdsRejectHighRate
    annotations:
      summary: "Istiod xds rejects rate increased"
      description: "Rate of number of XDS responses from pilot rejected by proxy\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: |-
      round(
        100 * increase(pilot_total_xds_rejects{app="istiod"}[5m]) / increase(pilot_xds_pushes{app="istiod"}[5m])
      ) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodDuplicateEnvoyClusters
    annotations:
      summary: "Istiod duplicate envoy clusters"
      description: "Istiod duplicate envoy clusters caused by service entries with same hostname\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      sum(rate(pilot_duplicate_envoy_clusters{}[5m])) > 0
    for: 1m
    labels:
      severity: warning    
  - alert: IstiodXDSInternalError
    annotations:
      summary: "Istiod XDS internal error"
      description: "Istiod XDS internal errors increased\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(pilot_total_xds_internal_errors[5m]) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodJWKSResolverNetworkFetchFail
    annotations:
      summary: "Istiod jwks resolver failure"
      description: "Total number of failed network fetch by pilot jwks resolver increased in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(pilot_jwks_resolver_network_fetch_fail_total[5m]) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodSDSCertificateErrors
    annotations:
      summary: "Istiod SDS certificate errors"
      description: "Total number of failures to fetch SDS key and certificate increased in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(pilot_sds_certificate_errors_total[5m]) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodSidecarInjectionFailure
    annotations:
      summary: "Istiod failed sidecar injection"
      description: "Total number of failed sidecar injection requests increased in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(sidecar_injection_failure_total[5m]) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodWebhookPatchFailure
    annotations:
      summary: "Istiod webhook patching total failures"
      description: "Webhook patching total failures increased in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(webhook_patch_failures_total[5m]) > 0
    for: 1m
    labels:
      severity: warning
  - alert: IstiodConfigRejects
    annotations:
      summary: "Istiod rejected configs"
      description: "Total number of configs that Pilot had to reject or ignore increased in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(pilot_total_rejected_configs[5m]) > 0
    for: 1m
    labels:
      severity: warning
- name: istiod-infra
  rules:
  - alert: IstiodContainerNotReady
    annotations:
      summary: "Istiod container not ready"
      description: "Container: discovery not ready\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      kube_pod_container_status_ready{container="discovery"} == 0
    for: 5m
    labels:
      severity: critical
  - alert: IstiodUnavailableReplica
    annotations:
      summary: "Istiod unavailable pod"
      description: "Istiod unavailable replica > 0\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      kube_deployment_status_replicas_unavailable{deployment=~"istiod.*"} > 0
    for: 5m
    labels:
      severity: critical
  - alert: IstiodContainerRestart
    annotations:
      summary: "Istiod container restarted recently"
      description: "Container: discovery restarted in last 5 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
    expr: >
      increase(kube_pod_container_status_restarts_total{container="discovery"}[5m]) > 0
    for: 1m
    labels:
      severity: critical
